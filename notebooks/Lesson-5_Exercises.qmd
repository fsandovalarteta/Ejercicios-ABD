---
title: "Tema 5: Ejercicio"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
editor: 
  markdown: 
    wrap: sentence
---

# Introducción

En este tema hemos estudiado el método de Monte Carlo.
Ahora vamos a ponerlo en práctica, comparando sus resultados con lo que ya conocemos de temas anteriores.
En esta ocasión, la entrega consiste en un ejercicio sobre el modelo normal-normal, y otro sobre .

Al igual que en el Tema 3, configuramos primero el entorno.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)


# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto  <- PALETA[1]
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica

# Redondea los números reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)
```

# Ejercicio 1: Modelo normal-normal

## Ajuste de modelos

En este ejercicio vamos a utilizar nuevamente el modelo normal-normal del [Ejercicio 4 del Tema 3](https://github.com/DV-Morillo/Ejercicios-ABD/blob/main/notebooks/Lesson-3_Exercises.qmd#L382).

Aquí tienes nuevamente los datos:

```{r normal-normal-muestras}
# Tiempo en s para leer un texto estándar en una prueba de lectura de las 2
#   clases de 1º de ESO en un colegio:
clase_1 <- tibble(
  id     = 1:27,
  tiempo = c(
    242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
    228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
    168, 250
  )
)

clase_2 <- tibble(
  id     = 1:24,
  tiempo = c(
    195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
    144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282
  )
)
```

Los datos de la distribución previa eran los datos de la población.
Recuerda:

```{r normal-normal-previa-params}
MU_PREVIA     <- 247
SIGMA2_PREVIA <-  34^2
```

Aplicando la propiedad de conjugación, recuerda que podemos obtener la expresión analítica de la distribución posterior de la media:

$p(\mu | y) = N(\mu_{post}, \sigma^2_{post})$,

siendo

$$
\mu\_{post} = \frac{\sigma^2_y \mu_{pre} + n \sigma^2_{pre} \bar{y}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

y

$$
\sigma^2\_{post} = \frac{\sigma^2_y \sigma^2_{pre}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

### Pregunta 1

-   Utilizando la expresión analítica del modelo, obtén la expresión analítica de la distribución posterior de la media para cada una de las dos clases, con 2 decimales.

::: {#respuesta-1 .callout-note}

Los datos previos para obtener la expresión analítica son el tamaño de la muestra, la media y la varianza de los dos grupos:

```{r respuesta-1.1}
# Tamaño de muestras
n_clase1 <- length(clase_1$tiempo)
n_clase2 <- length(clase_2$tiempo)

# Medias previas
media_pre_clase1 <- mean(clase_1$tiempo)
media_pre_clase2 <- mean(clase_2$tiempo)

# Varianzas previas
var_pre_clase1 <- sd(clase_1$tiempo)^2
var_pre_clase2 <- sd(clase_2$tiempo)^2

# Resultados
data.frame(clase = c("Clase 1", "Clase 2"),
           n_pre = c(n_clase1, n_clase2),
           media_pre = c(media_pre_clase1, media_pre_clase2),
           var_pre = c(var_pre_clase1, var_pre_clase2))
```

Ahora, a través del método analítico (bayesiano), la media y varianza de las distribuciones posteriores se obtendrían de la siguiente forma:

```{r respuesta-1.2}
# Media post analítica
media_post_clase1 <- (var_pre_clase1 * MU_PREVIA + n_clase1 * SIGMA2_PREVIA * media_pre_clase1) / (var_pre_clase1 + n_clase1 * SIGMA2_PREVIA)
media_post_clase2 <- (var_pre_clase2 * MU_PREVIA + n_clase2 * SIGMA2_PREVIA * media_pre_clase2) / (var_pre_clase2 + n_clase2 * SIGMA2_PREVIA)

# Varianza post analítica
var_post_clase1 <- (var_pre_clase1 * SIGMA2_PREVIA) / (var_pre_clase1 + n_clase1 * SIGMA2_PREVIA)
var_post_clase2 <- (var_pre_clase2 * SIGMA2_PREVIA) / (var_pre_clase2 + n_clase2 * SIGMA2_PREVIA)

# Resultados
data.frame(clase = c("Clase 1", "Clase 2"),
           media_post = c(media_post_clase1, media_post_clase2),
           var_post = c(var_post_clase1, var_post_clase2))
```
:::

## Simulación de Monte Carlo

Para cada familia de distribuciones de probabilidad existe la función `r*()` en R que permite simular valores de esa distribución.

Por ejemplo, en el caso de la normal, `rnorm(10, mean = 1, sd = 0)` extrae 10 muestras "independientes e igualmente distribuidas" de una distribución normal estándar.

### Pregunta 2

-   Para cada una de las dos clases, extrae 500 muestras de la distribución posterior.

*(Recomendación: Inicializa la "semilla aleatoria" para evitar tener valores diferentes en cada ejecución)*

```{r inicializa-semilla}
set.seed(20250318)
```

::: {#respuesta-2 .callout-note}

Utilizando el comando `rnorm` podemos estimar las dos distribuciones posteriores basadas en simulaciones de Monte Carlo:

```{r respuesta-2}
mc_clase1 <- rnorm(500, mean = media_post_clase1, sd = sqrt(var_post_clase1))
mc_clase2 <- rnorm(500, mean = media_post_clase2, sd = sqrt(var_post_clase2))

data.frame(mc_clase1, mc_clase2)
```
:::

## Inferencia con la media de la distribución posterior

### Pregunta 3

-   Con las distribuciones simuladas de la pregunta anterior, estima la media y la varianza de cada distribución. Compara los resultados con los obtenidos en la Pregunta 1.

::: {#respuesta-3 .callout-note}

Para estimar la media y la varianza de las simulaciones de Monte Carlo, utilizamos el siguiente código:

```{r respuesta-3.1}
# Medidas de la simulación MC para la clase 1
media_mc_clase1 <- mean(mc_clase1)
var_mc_clase1 <- sd(mc_clase1)^2

# Medidas de la simulación MC para la clase 2
media_mc_clase2 <- mean(mc_clase2)
var_mc_clase2 <- sd(mc_clase2)^2

# Resultados
data.frame(clase = c("Clase 1", "Clase 2"),
           media_analitica = c(media_post_clase1, media_post_clase1),
           var_analitica = c(var_post_clase1, var_post_clase2),
           media_mc = c(media_mc_clase1, media_mc_clase2),
           varianza_mc = c(var_mc_clase1, var_mc_clase2))
```
:::

## Tamaño muestral y error estándar de Monte Carlo

### Pregunta 4

-   Calcula el error estándar de Monte Carlo de las medias estimadas por el método de Monte Carlo [@hoff2009, p. 56], y su intervalo al 95% de confianza (p. 57). Asume que las varianzas verdaderas son desconocidas (i.e., utiliza las varianzas obtenidas por el método de Monte Carlo). ¿Cuál es la amplitud de los intervalos? Comprueba si los valores reales (obtenidos analíticamente) están comprendidos en los intervalos

::: {#respuesta-4 .callout-note}
El error estándar de Monte Carlo se obtiene a través de la siguiente fórmula:

$SE_{MC} = \sqrt{\frac{\widehat{\sigma}_\theta^2}{S}}$

Y el intervalo de confianza al 95% para la media posterior de $\theta$ se obtiene con la siguiente fórmula:

$\widehat{\theta} \pm 2 \sqrt{\frac{\widehat{\sigma}^2}{S}}$

Y para computarlo a través de R, utilizamos el siguiente código:

```{r respuesta-4.1}
# Estimación del error estándar de Monte Carlo
se_mc_clase1 <- sqrt(var_mc_clase1 / 500)
se_mc_clase2 <- sqrt(var_mc_clase2 / 500)

# Estimación de los intervalos de confianza al 95% (con quantile)
ic_mc_clase1 <- quantile(mc_clase1, c(0.025, 0.975))
ic_mc_clase2 <- quantile(mc_clase2, c(0.025, 0.975))

# Estimación de los intervalos de confianza al 95% (con fórmula)
ic_mc_clase1 <- c(media_mc_clase1 - 2 * sqrt(var_mc_clase1), media_mc_clase1 + 2 * sqrt(var_mc_clase1))
ic_mc_clase2 <- c(media_mc_clase2 - 2 * sqrt(var_mc_clase2), media_mc_clase2 + 2 * sqrt(var_mc_clase2))

# Resultados
data.frame(clase = c("Clase 1", "Clase 2"),
           se_mc = c(se_mc_clase1, se_mc_clase2),
           ic_95_inf = c(ic_mc_clase1[1], ic_mc_clase2[1]),
           ic_95_sup = c(ic_mc_clase1[2], ic_mc_clase2[2]))
```

A través de este cálculo se evidencia que el intervalo de confianza al 95% de la simulación de la clase 1 da valores entre 219 y 251, lo que genera una amplitud de 32 puntos. El valor real (media = 235) sí se encuentra comprendida entre dicho intervalo.

Similarmente, en la clase 2 el intervalo simulado está entre los valores de 207 y 237, lo que genera una amplitud de 30 puntos. El valor real (media = 222) también se encuentra comprendido en este intervalo.

De forma complementaria, podríamos observar la posición de los intervalos de confianza obtenidos por la simulación de Monte Carlo a través de los histogramas para cada simulación:

# Gráfico donde se muestra el intervalo de confianza y la media posterior verdadera
```{r respuesta-4.2}
mc_clases <- data.frame(mc_clase1, mc_clase2)

ggplot(mc_clases, aes(x = mc_clase1)) + 
  geom_histogram(color = PALETA[1], fill = "white") + 
  geom_vline(xintercept = ic_mc_clase1[1], color = PALETA[1], lwd = 1.2) + 
  geom_vline(xintercept = ic_mc_clase1[2], color = PALETA[1], lwd = 1.2) + 
  geom_vline(xintercept = 235, color = PALETA[2], lwd = 1.2) + 
  labs(title = "IC de simulación MC (verde) vs valor real (naranja) para clase 1")

ggplot(mc_clases, aes(x = mc_clase2)) + 
  geom_histogram(color = PALETA[3], fill = "white") + 
  geom_vline(xintercept = ic_mc_clase2[1], color = PALETA[3], lwd = 1.2) + 
  geom_vline(xintercept = ic_mc_clase2[2], color = PALETA[3], lwd = 1.2) + 
  geom_vline(xintercept = 222, color = PALETA[4], lwd = 1.2) + 
  labs(title = "IC de simulación MC (azul) vs valor real (rosado) para clase 2")
```
:::

### Pregunta 5

-   En base a las varianzas obtenidas por el método de Monte Carlo, determina el tamaño muestral de la distribución posterior necesario para alcanzar una precisión de 2 decimales en la estimación de la media de las distribuciones posteriores [@hoff2009, p. 56 ---vas a tener que "despejar" el tamaño de la muestra simulada]. Utiliza el valor mayor de ambas distribuciones para volver a calcular las medias, y comprueba si se alcanza la precisión esperada.

::: {#respuesta-5 .callout-note}
Según @hoff2009, si deseamos que la precisión sea menor a 0.01 (es decir, alcanzar una precisión de dos decimales), deberíamos aumentar nuestra muestra acorde a:

$$
2 \sqrt{\frac{\widehat{Var}^2}{S}} < 0.01
$$

Despejando S, sería:

$$
S > \frac{\widehat{Var}}{0.000025}
$$

Podemos calcular dicho valor, y todo el procedimiento posterior a través de los siguientes comandos:

```{r respuesta-5}
# Tamaño de simulación para una distribución con se_mc < 0.01

nuevo_s_clase1 <- round(var_post_clase1 / 0.000025,0)
nuevo_s_clase2 <- round(var_post_clase2 / 0.000025,0)

# Estimación con dicho tamaño de simulación

nuevo_mc_clase1 <- rnorm(nuevo_s_clase1, mean = media_post_clase1, sd = sqrt(var_post_clase1))
nuevo_mc_clase2 <- rnorm(nuevo_s_clase2, mean = media_post_clase2, sd = sqrt(var_post_clase2))

# Estimación de nuevas medias y varianzas

nueva_media_mc_clase1 <- mean(nuevo_mc_clase1)
nueva_var_mc_clase1 <- sd(nuevo_mc_clase1)^2

nueva_media_mc_clase2 <- mean(nuevo_mc_clase2)
nueva_var_mc_clase2 <- sd(nuevo_mc_clase2)^2

# Estimación del nuevo error estándar de Monte Carlo
nuevo_se_mc_clase1 <- sqrt(nueva_var_mc_clase1 / nuevo_s_clase1)
nuevo_se_mc_clase2 <- sqrt(nueva_var_mc_clase2 / nuevo_s_clase2)

# Resultados

data.frame(clase = c("Clase 1", "Clase 2"),
           var_post = c(var_post_clase1, var_post_clase2),
           nuevo_s = c(nuevo_s_clase1, nuevo_s_clase2),
           nueva_media_mc = c(nueva_media_mc_clase1, nueva_media_mc_clase2),
           nueva_var_mc = c(nueva_var_mc_clase1, nueva_var_mc_clase2),
           nuevo_se_mc = c(nuevo_se_mc_clase1, nuevo_se_mc_clase2))
```
Como se observa en el nuevo error estándar de la simulación Monte Carlo, el error es menor a 0.01, por lo que sí se logró dicha precisión.
:::

## Inferencia de intervalos y probabilidades

### Pregunta 6

-   Utilizando las distribuciones de alta precisión obtenidas en la Pregunta 5, calcula:

    -   Los intervalos de credibilidad del 99% de las distribuciones posteriores.

    -   Los cuartiles de las distribuciones posteriores.

    -   La probabilidad de cada clase de tener una media menor a la de la población.

Obtén los resultados analíticos con las funciones `qnorm()` y `pnorm()`, y compara ambos.

::: {#respuesta-6 .callout-note}
```{r respuesta-6}

# Estimación de los nuevos intervalos de confianza al 99%

ic_clase1 <- qnorm(p = c(0.005, 0.995), mean = media_post_clase1, sd = sqrt(var_post_clase1))
ic_clase2 <- qnorm(p = c(0.005, 0.995), mean = media_post_clase2, sd = sqrt(var_post_clase2))

# Estimación de cuartiles

cuartiles_clase1 <- qnorm(p = c(0.25, 0.5, 0.75), mean = media_post_clase1, sd = sqrt(var_post_clase1))
cuartiles_clase2 <- qnorm(p = c(0.25, 0.5, 0.75), mean = media_post_clase2, sd = sqrt(var_post_clase2))

# Probabilidad de que cada clase tenga una media inferior a la real (media = 235)

prob_clase1 <- pnorm(q = 235, mean = media_post_clase1, sd = sqrt(var_post_clase1))
prob_clase2 <- pnorm(q = 222, mean = media_post_clase2, sd = sqrt(var_post_clase2))

# Resultados
data.frame(clase = c("Clase 1", "Clase 2"),
           IC_95_inf = c(ic_clase1[1], ic_clase2[1]),
           IC_95_sup = c(ic_clase1[2], ic_clase2[2]),
           q_25 = c(cuartiles_clase1[1], cuartiles_clase2[1]),
           q_50 = c(cuartiles_clase1[2], cuartiles_clase2[2]),
           q_75 = c(cuartiles_clase1[3], cuartiles_clase2[3]),
           prob_50_poblacion = c(prob_clase1, prob_clase2))
```
En la tabla resumen podemos apreciar que el rango de valores del intervalo de confianza es ligeramente mayor en la clase 1 (44) que en la clase 2 (42). Así mismo, la probabilidad de que la clase 1 tenga una media menor a la de la población es de 50.9%, mientras que para la clase 2 es de 94%.
:::

## Reflexión sobre el método de Monte Carlo

### Pregunta 7

-   ¿Qué opinas del método de Monte Carlo? ¿Te resulta fácil o difícil de aplicar? ¿Qué consideras que aporta respecto de obtener los parámetros de los modelos aplicando las fórmulas analíticas?

::: {#respuesta-7 .callout-note}
Creo que es bastante fácil de aplicar y, a pesar que puede requerir mucho tiempo de procesamineto si las simulaciones son muy grandes.
Específicamente, creo que es útil por la flexibilidad que tiene para aplicarse a todos los tipos de distribución (normal, binomial, gamma, beta, etc.).
En cambio, los métodos analíticos suelen basarse principalmente en modelos conjugados para que la distribución posterior sea de la misma familia que la prior.

A nivel matemático, a través del método MC no es necesario aplicar fórmulas complejas ni realizar derivaciones matemáticas, ni tiene que cumplir con algunos supuestos estadísticos específicos de cada distribución.
:::

## Inferencia con funciones derivadas

### Pregunta 8

-   Calcula la probabilidad de que la media de la segunda clase sea superior a la media de la primera clase usando el método de Monte Carlo. ¿Cómo lo harías usando la fórmula analítica? ¿Es más fácil o más difícil?

::: {#respuesta-8 .callout-note}

Debido a que, a través de los previos ejercicios tenemos dos estimaciones de MC (una de 500 simulaciones y otra de > 2.5 millones), la estimación de dichas probabilidades se realizan con comandos sencillos:

```{r respuesta-8.1}
# Método MC en la estimación con 500 simulaciones
prob_mc_500 <- mean(mc_clase2 > mc_clase1)

# Método MC en la estimación con > 2.5 millones de simulaciones
prob_mc_2.5m <- mean(nuevo_mc_clase2 > nuevo_mc_clase1)
```

Sin embargo, a través de la fórmula analítica tenemos que partir de la idea que, como las medias posteriores son normales, la diferencia entre dichas medias también tendrá una distribución normal, y asumimos que se estima de la siguiente forma:

$$
\delta \sim \mathcal{N}(\mu_2 - \mu_1, \sigma_1^2 + \sigma_2^2)
$$

Siendo $\delta = \theta_2 - \theta_1$

Como lo que queremos probar es la probabilidad de que la media posterior de la clase 2 sea mayor que la de la clase 1, la fórmula sería la integral de la función de distribución acumulada (CDF) de la normal estándar para dicha comparación, de la siguiente forma:

$$
P(\theta_1 > \theta_2) = P(\delta > 0) = 1 - \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi(\sigma_1^2 + \sigma_2^2)}} \exp\left(-\frac{\left(t - (\mu_2 - \mu_1)\right)^2}{2(\sigma_1^2 + \sigma_2^2)}\right) \, dt
$$

Esta integral se puede estimar en R con el comando `pnorm` y poder compararlo con los resultados de las estimación a través de la simulación de Monte Carlo:

```{r respuesta-8.2}
# Método analítico asumiendo distribuciones normales

dif_medias <- media_post_clase2 - media_post_clase1
dif_sd <- sqrt(var_post_clase2 + var_post_clase1)
prob_analitica <- 1 - pnorm(0, mean = dif_medias, sd = dif_sd)

# Resultados
data.frame(prob_mc_500, prob_mc_2.5m, prob_analitica)
```
La fórmula analítica es más compleja y requiere mayor cálculo. En cambio, a partir de simulaciones sucesivas (con la suficiente capacidad de computación), el método de MC resulta más sencillo.
:::

### Pregunta 9

-   Las muestras obtenidas para distribución posterior de la media de cada una de las dos clases son independientes. Por lo tanto, debería dar igual en qué orden se hayan muestreado. Utilizando `sample(_vector_)` podemos obtener los valores aleatorizado del vector en un objeto `_vector_`. Comprueba si se cumple que podemos aleatorizar las muestras de una (o ambas) distribuciones posteriores, y que la probabilidad de que las dos clases sean diferentes aún así no cambie.

::: {#respuesta-9 .callout-note}
```{r respuesta-9}
# Asumiendo que la "seed" del ejercicio es 20250318

# Muestra aleatoria de la simulación de MC para ambas clases
muestra_aleatoria_mc_clase1 <- sample(mc_clase1)
muestra_aleatoria_mc_clase2 <- sample(mc_clase2)

# Probabilidad de la diferencia
prob_muestra_aleatoria <- mean(muestra_aleatoria_mc_clase2 > muestra_aleatoria_mc_clase1)

# Resultados
data.frame(prob_mc_500, prob_mc_2.5m, prob_muestra_aleatoria)

```
La probabilidad basada en muestras aleatorias resulta muy similar a la diferencia en las simulaciones de MC (de 500 y 2.5 millones). Sin embargo, debido al azar, cada vez que se corra puede obtener un resultado diferente.
:::

## Estimador máximo posterior

El estimador máximo posterior (MAP) de la media es, simplemente, la moda de la distribución posterior.
Es decir, el valor de la media para el que la densidad de la distribución posterior es máxima.

Con la expresión cerrada de la distribución posterior normal, sabemos que la moda coincide con el valor central o media.

Con cualquier otra expresión cerrada, podemos utilizar un algoritmo de optimización para encontrar ese máximo.

Cuando no conocemos la expresión cerrada, sin embargo, necesitaremos utilizar el método de Monte Carlo (veremos cómo en un tema posterior).
No obstante, obtener la moda a partir de una muestra es algo más complicado que simplemente "resumir" las muestras de la distribución posterior.

Una forma de hacerlo es utilizando un histograma.
Sin embargo, esto es "rudimentario", y no está claro qué ancho deben tener las bandas.

La forma idónea es obteniendo la densidad mediante un "suavizado", algoritmo llamado "kernel density estimation".

Vamos a ver un ejemplo con una distribución normal estándar.
Sabemos que el algoritmo debería devolver el valor "0", que se corresponde con el máximo de esta distribución.

```{r map-mc-normal-estandar}
N_MC <- 50000L # Tamaño muestral para la simulación de la distribuión.

muestras_norm <- rnorm(N_MC) # Simulamos las muestras de la distribución

densidad_norm <- density(muestras_norm) # `density()` aplica el "suavizado"

# Convertimos la densidad en un "tibble" para manejarla más fácilmente 
densidad_normal <- tibble(
  x        = densidad_norm$x, # `x` == variable aleatoria
  densidad = densidad_norm$y
)

# Podemos representar la densidad gráficamente, junto con la curva normal:
densidad_normal |>
  mutate(dens_analitica = dnorm(x)) |>
  ggplot(aes(x, densidad)) +
  geom_line(color = color_defecto) +
  geom_line(aes(y = dens_analitica), color = PALETA[2])

# Obtenemos el valor de la moda:
estimador_map <- densidad_normal |> slice(which.max(densidad))
densidad_max  <- estimador_map |> pull(densidad)
moda          <- estimador_map |> pull(x)
```

El estimador MAP es `{r} moda`, siendo su densidad `{r} densidad_max`.

### Pregunta 10

-   Utilizando las muestras posteriores obtenidas en la pregunta 5, calcula los estimadores MAP para las dos clases, y compáralos con los que obtendrías con las fómulas analíticas.

::: {#respuesta-10 .callout-note}

Desde una forma gráfica, podemos observar la distribución de las estimaciones MC junto con la media verdadera para ambos grupos:

```{r respuesta-10.1}
df <- data.frame()

ggplot(df, aes(x = nuevo_mc_clase1, y = after_stat(density))) + 
  geom_density(color = PALETA[1]) + 
  geom_vline(xintercept = 235, color = PALETA[2], lwd = 1.2) + 
  labs(title = "Densidad de simulación de MC (verde) y valor real (naranja) en clase 1")

ggplot(df, aes(x = nuevo_mc_clase2, y = after_stat(density))) + 
  geom_density(color = PALETA[3]) + 
  geom_vline(xintercept = 222, color = PALETA[4], lwd = 1.2) + 
  labs(title = "Densidad de simulación de MC (azul) y valor real (rosado) en clase 2")
```
Para estimar la probabilidad máxima a posteriori (MAP), la densidad máxima y la moda podemos emplear los siguientes comandos:

```{r respuesta-10.2}
# Estimación de la densidad de ambos modelos
densidad_clase1 <- data.frame(x = density(nuevo_mc_clase1)$x,
                              y = density(nuevo_mc_clase1)$y)
densidad_clase2 <- data.frame(x = density(nuevo_mc_clase2)$x,
                              y = density(nuevo_mc_clase2)$y)

# Densidad máxima
densidad_max_clase1 <- max(densidad_clase1$y)
densidad_max_clase2 <- max(densidad_clase2$y)

# Valores MAP
map_clase1 <- densidad_clase1$x[which.max(densidad_clase1$y)]
map_clase2 <- densidad_clase2$x[which.max(densidad_clase2$y)]

# Moda, que es teóricamente igual a la MAP
moda_clase1 <- map_clase1
moda_clase2 <- map_clase2
```

Desde la perspectiva analítica, como ambas distribuciones son normales, en teoría la media, mediana y moda poseen el mismo valor. Por ello, podemos comparar el resultado de las estimaciones del MAP y la moda con la media posterior analítica:

```{r respuesta-10.3}
# Resultados

data.frame(clase = c("Clase 1", "Clase 2"),
           MAP = c(map_clase1, map_clase2),
           densidad_max = c(densidad_max_clase1, densidad_max_clase2),
           moda = c(moda_clase1, moda_clase2),
           media_post_analitica = c(media_post_clase1, media_post_clase2))
```
:::

# Ejercicio 2: Distribuciones Gamma

## Diferencia entre distribuciones

En el texto de @hoff2009 se utiliza una distribución Gamma en un ejemplo comparando las tasas de fertilidad de mujeres de 40 años con y sin título universitario, obtenido de la Encuesta Social General de los EEUU durante los años 1990 [puedes consultar los detalles en el capítulo 3 de @hoff2009].
Las distribuciones posteriores de la tasa de fertilidad de cada grupo son (p. .53):

$$
p(\theta_{sin} | y) = gamma(\theta_{sin}, 219, 112)
$$

$$
p(\theta_{con} | y) = gamma(\theta_{con}, 68, 45)
$$

La distribución Gamma está implementada en R mediante la familia de funciones `*gamma()`: `rgamma()`, `dgamma()`, `pgamma()`, y `qgamma()`.

### Pregunta 11

-   Utilizando un eje horizontal con precisión de .002, representa las dos distribuciones. Determina los límites del eje horizontal según tu propio criterio. Sin ver la forma de la función de densidad, ¿podrías deducir cuál habría de ser alguno de los dos límites del intervalo?

::: {#respuesta-11 .callout-note}

Según los datos obtenidos en el ejemplo de @hoff2009, la muestra de mujeres con educación superior fue de $n = 44$, el total de hijos reportados fue $\sum y_i = 66$ y los parámetros iniciales fueron $a = 2, b = 1$.

Por otro lado, la muestra de mujeres sin educación superior fue de $n = 111$, el total de hijos reportados fue de $\sum y_i = 217$ y asumimos que los parámetros iniciales también fueron $a = 2, b = 1$.

Sin embargo, como estamos trabajando desde un análisis bayesiano, directamente trabajaríamos con distribuciones posteriores $a+\sum y_i, b+n$

Podríamos deducir cuáles podrían ser los límites a través de estimar la media y la desviación estándar, e identificar qué valores podrían estar a los extremos (por ejemplo, -3 sd ó +3 sd):

```{r respuesta-11.1}
a <- 2 ; b <- 1
n_sin <- 111 ; n_con <- 44
sy_sin <- 217 ; sy_con <- 66
a_sin_post <- a + sy_sin ; b_sin_post <- b + n_sin
a_con_post <- a + sy_con ; b_con_post <- b + n_con

media_gamma_sin <- (a_sin_post) / (b_sin_post)
var_gamma_sin <- (a_sin_post)/(b_sin_post)^2

media_gamma_con <- (a_con_post) / (b_con_post)
var_gamma_con <- (a_con_post)/(b_con_post)^2

data.frame(grupos = c("Sin título", "Con título"),
           media = c(media_gamma_sin, media_gamma_con),
           varianza = c(var_gamma_sin, var_gamma_con),
           lím_inf = c(media_gamma_sin -3 * sqrt(var_gamma_sin), media_gamma_con -3 * sqrt(var_gamma_con)),
           lím_sup = c(media_gamma_sin +3 * sqrt(var_gamma_sin), media_gamma_con +3 * sqrt(var_gamma_con)))
```

Ahora, para representar ambas distribuciones de forma gráfica, podemos emplear la siguiente fórmula:

```{r respuesta-11.2}
# Aquí agregaremos la precisión solicitada por el ejercicio y el rango de valores del eje x
precision <- seq(from = 0.5, to = 2.5, by = 0.002)

# Tabla para facilitar los datos a ggplot2
gamma <- data.frame(theta = precision,
                    densidad_sin = dgamma(precision, shape = 219, rate = 112),
                    densidad_con = dgamma(precision, shape = 68, rate = 45))

ggplot(gamma, aes(x = precision)) + 
  geom_line(y = gamma$densidad_sin, color = PALETA[1]) + 
  geom_line(y = gamma$densidad_con, color = PALETA[2]) + 
  scale_y_continuous(limits = c(0, 3.2)) + 
  labs(title = "Distribuciones gamma posteriores sobre la cantidad de hijos por mujeres de \n 40 años sin educación universitaria (verde) y con educación universitaria (naranja)")
```
:::

### Pregunta 12

-   Determina la probabilidad de que las mujeres de 40 años sin título universitario en los 90 en EEUU tuvieran una tasa de fertilidad superior a la de las mujeres con título universitario. Utiliza el método de Monte Carlo con 3 decimales de precisión al 99% de confianza, justificando el tamaño muestral elegido para aproximar las distribuciones posteriores (usa la media para justificar esta precisión). Si lo necesitas, revisa el material complementario del Tema 3 para determinar la varianza de la distribución Gamma.

::: {#respuesta-12 .callout-note}

Utilizando la fórmula previa de @hoff2009, si tuviéramos que estimar una simulación con una precisión de 3 decimales (< 0.001), la fórmula sería así:

$$
2 \sqrt{\frac{\widehat{Var}}{S}} < 0.001
$$

Y despejando S, sería:

$$
\frac{\widehat{Var}}{0.00000025} < S
$$

Ahora, debido a que el ejercicio se centra en la comparación de dos grupos, la varianza a utilizar para estimar la cantidad de simulaciones sería la suma de varianzas. En este sentido,  estimación de la nueva S debería programarse de la siguiente forma:

```{r respuesta-12}

# Forma a través de MC

nueva_s_gamma_sin <- var_gamma_sin/0.00000025
nueva_s_gamma_con <- var_gamma_con/0.00000025

gamma_mc_sin <- rgamma(nueva_s_gamma_sin, shape = a_sin_post, scale = b_sin_post)
gamma_mc_con <- rgamma(nueva_s_gamma_con, shape = a_con_post, scale = b_con_post)

prob_gamma_mc <- mean(gamma_mc_sin > gamma_mc_con)

# Forma analítica

dif_medias_gamma <- mean(gamma_mc_sin) - mean(gamma_mc_con)
dif_sd_gamma <- sqrt(var_gamma_sin + var_gamma_con)
prob_analitica_gamma <- 1 - pnorm(0, mean = dif_medias_gamma, sd = dif_sd_gamma)

# Estimación del nuevo error estándar de Monte Carlo
se_mc_gamma_sin <- sqrt(gamma_mc_sin / nueva_s_gamma_sin)
se_mc_gamma_con <- sqrt(gamma_mc_con / nueva_s_gamma_con)

# Resultados

data.frame(prob_gamma_mc, prob_analitica_gamma)
```

En ambos casos, la probabilidad es prácticamente del 100%. Es decir, hay una probabilidad del casi 100% de que las mujeres de 40 años sin educación universitaria tengan en promedio más hijos que las mujeres de 40 años con educación universitaria.
:::

# Referencias
