---
title: "Tema 3: Ejercicios"
format:
  html:
    code-copy:       true
    code-tools:      true
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
callout-appearance: minimal
---
 
# Introducción

En este hemos visto los fundamentos del modelado Bayesiano, y vamos a aplicarlos desde un punto de vista teórico en los ejercicios a continuación.

En primer lugar, configuramos el entorno para ejecutar el código.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)


# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto  <- PALETA[1]
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica
```

Verás que solamente necesitamos el paquete {tidyverse}, para manipular datos, y configurar la salida gráfica (el paquete {RColorBrewer} sólo se utiliza para obtener una paleta de colores agradable y accesible para personas con ceguera al color).
No hace falta ningún paquete para análisis y modelado Bayesiano, ya que los modelos que vamos a estimar se basan en las propiedades analíticas de las *distribuciones conjugadas*.

# Ejercicio 1

## Distribución uniforme

A continuación se muestra el código en R para representar la distribución uniforme $x \sim U(0, 1)$:

```{r ejemplo-uniforme}
PREC     <- 1e-3 # Precisión para representar la función de densidad (milésimas)
DENS_INF <- 0    # Rango inferior de la función de densidad
DENS_SUP <- 1    # Rango superior de la función de densidad

uniforme <- tibble( # Esta función crea un "data.frame" o tabla de datos
  variable = seq(from = DENS_INF, to = DENS_SUP, by = PREC),
  densidad = variable |> dunif(min = DENS_INF, max = DENS_SUP)
)

uniforme |> glimpse() # Muestra el objeto con los datos, contiene 2 columnas 

uniforme |> # Usando la tabla de datos antes creada, crea un objeto gráfico
  ggplot(mapping = aes(x = variable, y = densidad)) + # "Mapea" columnas a
                                                      #   coordenadas
  geom_line(color = color_defecto) + # Representa mediante una línea continua
  
  ylim( # Fija el límite inferior a 0 para mostrar el eje y completo:
    0,  # (Usa la propia distribución para establecer el límite superior)
    uniforme |> pull(densidad) |> max()
  )
```

## Distribución normal

Aplicando un código similar, se puede representar una distribución normal estandarizada $x \sim N(0, 1)$:

```{r ejemplo-normal}
DENS_INF <- -4 # Usamos un rango más adecuado para la normal estandarizada
DENS_SUP <-  4

normal <- tibble( # Reutilizamos `PREC` del "chunk" de código anterior
  variable = seq(from = DENS_INF, to = DENS_SUP, by = PREC),
  densidad = variable |> dnorm()
)

# Al cubrir la distribución el rango desde 0 hasta el máximo, en este caso no
#   es necesario establecer los límites manualmente
normal |>
  ggplot(mapping = aes(x = variable, y = densidad)) +
  geom_line(color = color_defecto)
```

Como puedes ver, los límites se establecen automáticamente para cubrir todo el rango de la distribución (no hace falta fijarlos).
Al haber valores próximos a 0, tampoco es necesario establecer el límite inferior manualmente.

## Integración "numérica"

Haciendo uso de los valores generados de una distribución, podemos operar con ellos para obtener los resultados de "integrar" esa función, pero haciéndolo de forma numérica.

Al obtener "valores equiespaciados" de la distribución, lo que estamos obteniendo es una "rejilla" de valores.
La integración será una suma de "rectángulos", de altura igual a la densidad en ese punto, con base centrada en ese punto y extenciéndose `PREC/2` hacia cada lado (y por tanto de anchura `PREC`).

Utilizando esta "integral numérica", podemos obtener ciertos valores de la distribución.
Por ejemplo, la integral en todo el dominio de la variable debería tener un valor de 1.

```{r integral-uniforme}
uniforme |> summarize(integral = PREC * sum(densidad))
```

En el caso de la distribución uniforme, tenemos valores "centrados" en 0 y 1, por lo que los intervalos de los extremos se extienden hasta `-PREC/2` y `1 + PREC/2`.
Podríamos "restar medio valor" de la densidad en cada extremo para obtener una integral más precisa:

```{r}
uniforme |> summarize(
  integral = PREC * (sum(densidad) - 0.5 * (first(densidad) + last(densidad)))
)
```

En el caso de la distribución normal el cálculo de la integral se haría igual:

```{r integral-normal}
normal |> summarize(
  integral = sum(densidad) * PREC
)
```

En este caso, el dominio es infinito, pero nos hemos restringido al rango $[`{r} DENS_INF`, `{r} DENS_SUP`]$.
Por lo tanto, estamos desechando la parte de la distribución que está en las "colas".
También, cuanto mayor sea la precisión, más se acercará la aproximación mediante "rectángulos" a la curva real.

```{r integral-normal-mas-precisa}
tibble( # Ampliando el rango a [-10, 10]:
  variable = seq(from = -10, to = 10, by = PREC),
  densidad = variable |> dnorm()
) |>
  summarize(integral = sum(densidad) * PREC)

tibble( # Usando precisión de "millonésimas":
  variable = seq(from = DENS_INF, to = DENS_SUP, by = 1e-6),
  densidad = variable |> dnorm()
) |>
  summarize(integral = sum(densidad) * 1e-6) # Misma precisión en la integral
```

En general, las aproximaciones iniciales pueden ser válidas.
Si lo necesitamos, podemos "normalizar" por la integral.
Los siguiente ejemplos, triviales, pueden ayudarnos más adelante:

```{r integral-normalizada}
uniforme |> summarize(
  integral = PREC * sum(densidad),
  integral = integral / integral # Normalización
)

normal |> summarize(
  integral = PREC * sum(densidad),
  integral = integral / integral # Normalización
)
```

## Práctica

Calcula o comprueba las siguientes respuestas usando comandos de R:

### Pregunta 1

-   ¿Cuál es el valor máximo de la función de densidad de la distribución normal?

::: {#respuesta-1 .callout-note}

Podemos obtener este valor en R a través del siguiente comando:

```{r respuesta-1}
max(normal$densidad)
```

El valor máximo de la función de densidad es 0.3989

:::

### Pregunta 2

-   ¿Para qué valor de la variable aleatoria se da? ¿Cómo llamarías a ese valor?

::: {#respuesta-2 .callout-note}

En una distribución normal, el valor máximo que puede tomar la función (curva) de densidad es cuando un valor toma el mismo que la media. Si tomamos como ejemplo el gráfico de la curva normal para este ejercicio:


```{r respuesta-2.1}
normal |>
  ggplot(mapping = aes(x = variable, y = densidad)) +
  geom_line(color = color_defecto)
```

A este valor máximo lo llamamos la moda, ya que es el valor más frecuente o probable en la distribución. En una distribución normal, este punto coincide con la media y la moda. Este punto también es el punto central del eje X (cuando vale 0), el cual coincide con  la posición de la moda, media y mediana.

Por ello, el valor de la moda (y por ende, el de la media y la mediana) también podemos obtenerla si le pedimos a R que nos diga el valor de densidad cuando la variable toma el valor de 0:

```{r respuesta-2.2}
subset(normal, variable == 0)$densidad
```

:::

### Pregunta 3

-   El valor máximo, ¿puede ser mayor que 1? Justifica tu respuesta.

::: {#respuesta-3 .callout-note}

En el caso de una distribución normal, el valor máximo "per se" que puede tomar la función de distribución puede ser un valor superior a 1, pero en dicha curva, el área total bajo la curva siempre debe ser igual a 1.

:::

### Pregunta 4

-   Calcula la función de distribución de la variable normal **a partir de los valores de la función de densidad obtenidos previamente**, y represéntala.

*(Ejecuta `?cumsum` para consultar la ayuda de esa función).*

::: {#respuesta-4 .callout-note}

La función de distribución para describir la probabilidad acumulada de la variable normal se expresa de la siguiente forma:

\begin{equation}
F(y) = \int_{-\infty}^{y} \frac{1}{\sigma \sqrt{2\pi}} \exp\left\{ -\frac{1}{2} \left( \frac{t - \mu}{\sigma} \right)^2 \right\} \, dt
\end{equation}

Para expresarla en R, podemos crear una nueva variable que genere la suma acumulativa de la función de densidad:

```{r respuesta-4.1}

normal$cdf <- cumsum(normal$densidad)

head(normal$cdf)
tail(normal$cdf)

```

y representado de forma gráfica:

```{r respuesta-4.2}

normal |>
  ggplot(mapping = aes(x = variable, y = cdf)) +
  geom_line(color = color_defecto)

```

:::

### Pregunta 5

-   Calcula el valor esperado de la distribución normal.

::: {#respuesta-5 .callout-note}

El valor esperado, entendido como la media, de la distribución normal se obtendría de la siguiente forma (redondeada a 5 decimales):

```{r respuesta-5}
print(round(sum(normal$variable * normal$densidad) * PREC),5)
```

El valor promedio que podría tomar la función de distribución normal es 0.

:::

# Ejercicio 2

## Distribución Beta

### Pregunta 6

-   Representa una distribución Beta con parámetros $\alpha$ = $\beta$ = 1, $Beta(1, 1)$. Ajusta los ejes correctamente, si hace falta, como en la distribución uniforme.

*(Si no sabes qué limites utilizar, consulta la ayuda de `dbeta()`).*

::: {#respuesta-6 .callout-note}

```{r respuesta-6}
beta <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1, shape2 = 1))

beta |>
  ggplot(mapping = aes(x = variable, y = beta)) +
  geom_line(color = color_defecto) +
  ylim(0, uniforme |> pull(densidad) |> max())
```

:::

### Pregunta 7

-   ¿Qué forma tiene?

::: {#respuesta-7 .callout-note}

Tiene forma de una línea horizontal de valor 1 en el eje y, a lo largo de todo el eje x.

:::

## Parámetros de la distribución Beta

### Pregunta 8

-   Prueba con diferentes valores de $\alpha$ y $\beta$.

::: {#respuesta-8 .callout-note}
```{r respuesta-8}

beta_ejemplo_1 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.5, shape2 = 0.5))

beta_ejemplo_2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1, shape2 = 1))

beta_ejemplo_3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.5, shape2 = 1.5))

beta_ejemplo_4 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 2))

beta_ejemplo_5 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2.5, shape2 = 2.5))

beta_ejemplo_6 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 3, shape2 = 3))

beta_ejemplos <- bind_rows(
  beta_ejemplo_1 %>% mutate(grupo = "beta = 0.5, alpha = 0.5"),
  beta_ejemplo_2 %>% mutate(grupo = "beta = 1.0, alpha = 1.0"),
  beta_ejemplo_3 %>% mutate(grupo = "beta = 1.5, alpha = 1.5"),
  beta_ejemplo_4 %>% mutate(grupo = "beta = 2.0, alpha = 2.0"),
  beta_ejemplo_5 %>% mutate(grupo = "beta = 2.5, alpha = 2.5"),
  beta_ejemplo_6 %>% mutate(grupo = "beta = 3.0, alpha = 3.0")
)

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplo_1, beta_ejemplo_2, beta_ejemplo_3, beta_ejemplo_4, beta_ejemplo_5, beta_ejemplo_6, beta_ejemplos)
```

:::

### Pregunta 9

-   ¿Qué ocurre a medida que van creciendo?

::: {#respuesta-9 .callout-note}

A medida que ambos números crecen, se empieza a formar una curva en forma de campana.

:::

### Pregunta 10

-   ¿Qué ocurre cuando son iguales? ¿Y cuándo son distintos?

::: {#respuesta-10 .callout-note}

Si aplicamos cambios en el primer coeficiente, empezamos a observar que la curva genera una asimetría hacia la izquierda (es decir, empiezan a aparecer más posibles valores en la izquierda de la curva, comparado a la derecha)

```{r respuesta-10.1}
beta_ejemplo_1 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 2))

beta_ejemplo_2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2.5, shape2 = 2))

beta_ejemplo_3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 3, shape2 = 2))

beta_ejemplo_4 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 3.5, shape2 = 2))

beta_ejemplo_5 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 4, shape2 = 2))

beta_ejemplo_6 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 4.5, shape2 = 2))

beta_ejemplos <- bind_rows(
  beta_ejemplo_1 %>% mutate(grupo = "beta = 2.0, alpha = 2.0"),
  beta_ejemplo_2 %>% mutate(grupo = "beta = 2.5, alpha = 2.0"),
  beta_ejemplo_3 %>% mutate(grupo = "beta = 3.0, alpha = 2.0"),
  beta_ejemplo_4 %>% mutate(grupo = "beta = 3.5, alpha = 2.0"),
  beta_ejemplo_5 %>% mutate(grupo = "beta = 4.0, alpha = 2.0"),
  beta_ejemplo_6 %>% mutate(grupo = "beta = 4.5, alpha = 2.0")
)

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplo_1, beta_ejemplo_2, beta_ejemplo_3, beta_ejemplo_4, beta_ejemplo_5, beta_ejemplo_6, beta_ejemplos)

```

En cambio, si aplicamos cambios en el segundo coeficiente, empezamos a observar que la curva genera una asimetría hacia la derecha (es decir, empiezan a aparecer más posibles valores en la derecha de la curva, comparado a la izquierda)

```{r respuesta-10.2}
beta_ejemplo_1 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 2))

beta_ejemplo_2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 2.5))

beta_ejemplo_3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 3))

beta_ejemplo_4 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 3.5))

beta_ejemplo_5 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 4))

beta_ejemplo_6 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 2, shape2 = 4.5))

beta_ejemplos <- bind_rows(
  beta_ejemplo_1 %>% mutate(grupo = "beta = 2.0, alpha = 2.0"),
  beta_ejemplo_2 %>% mutate(grupo = "beta = 2.0, alpha = 2.5"),
  beta_ejemplo_3 %>% mutate(grupo = "beta = 2.0, alpha = 3.0"),
  beta_ejemplo_4 %>% mutate(grupo = "beta = 2.0, alpha = 3.5"),
  beta_ejemplo_5 %>% mutate(grupo = "beta = 2.0, alpha = 4.0"),
  beta_ejemplo_6 %>% mutate(grupo = "beta = 2.0, alpha = 4.5")
)

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplo_1, beta_ejemplo_2, beta_ejemplo_3, beta_ejemplo_4, beta_ejemplo_5, beta_ejemplo_6, beta_ejemplos)

```
:::

### Pregunta 11

-   ¿Qué ocurre si tienen valores ligeramente superiores a 1?

::: {#respuesta-11 .callout-note}

Si se toman valores ligeramente superiores a 1, la línea recta empieza a volverse cada vez más una curva en forma de campana.

```{r respuesta-11}
beta_ejemplo_1 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1, shape2 = 1))

beta_ejemplo_2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.1, shape2 = 1.1))

beta_ejemplo_3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.2, shape2 = 1.2))

beta_ejemplo_4 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.3, shape2 = 1.3))

beta_ejemplo_5 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.4, shape2 = 1.4))

beta_ejemplo_6 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1.5, shape2 = 1.5))

beta_ejemplos <- bind_rows(
  beta_ejemplo_1 %>% mutate(grupo = "beta = 1.0, alpha = 1.0"),
  beta_ejemplo_2 %>% mutate(grupo = "beta = 1.1, alpha = 1.1"),
  beta_ejemplo_3 %>% mutate(grupo = "beta = 1.2, alpha = 1.2"),
  beta_ejemplo_4 %>% mutate(grupo = "beta = 1.3, alpha = 1.3"),
  beta_ejemplo_5 %>% mutate(grupo = "beta = 1.4, alpha = 1.4"),
  beta_ejemplo_6 %>% mutate(grupo = "beta = 1.5, alpha = 1.5")
)

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplo_1, beta_ejemplo_2, beta_ejemplo_3, beta_ejemplo_4, beta_ejemplo_5, beta_ejemplo_6, beta_ejemplos)

```

:::

### Pregunta 12

-   ¿Qué ocurre si tienen valores por debajo de 1?

::: {#respuesta-12 .callout-note}

La línea recta empieza a tener una forma de "U" o como un cuadrado sin la línea superior de éste.

```{r respuesta-12}
beta_ejemplo_1 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1, shape2 = 1))

beta_ejemplo_2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.9, shape2 = 0.9))

beta_ejemplo_3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.8, shape2 = 0.8))

beta_ejemplo_4 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.7, shape2 = 0.7))

beta_ejemplo_5 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.6, shape2 = 0.6))

beta_ejemplo_6 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 0.5, shape2 = 0.5))

beta_ejemplos <- bind_rows(
  beta_ejemplo_1 %>% mutate(grupo = "beta = 1.0, alpha = 1.0"),
  beta_ejemplo_2 %>% mutate(grupo = "beta = 0.9, alpha = 0.9"),
  beta_ejemplo_3 %>% mutate(grupo = "beta = 0.8, alpha = 0.8"),
  beta_ejemplo_4 %>% mutate(grupo = "beta = 0.7, alpha = 0.7"),
  beta_ejemplo_5 %>% mutate(grupo = "beta = 0.6, alpha = 0.6"),
  beta_ejemplo_6 %>% mutate(grupo = "beta = 0.5, alpha = 0.5")
)

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplo_1, beta_ejemplo_2, beta_ejemplo_3, beta_ejemplo_4, beta_ejemplo_5, beta_ejemplo_6, beta_ejemplos)

```
:::

# Ejercicio 3

*(NOTA: Para todas las distribuciones, utiliza el valor de `PREC` definido en el ejercicio 1.)*

## Modelo beta-binomial

En el departamento de investigación de mercado de tu empresa quieren saber la tasa de aceptación de la nueva app que quieren lanzar.
Para ello, han probado la app con una muestra (asume m.a.s.) de $n$ potenciales usuarios/as, y se les ha pedido que indiquen si descargarían o no la app.

El jefe del departamento de analítica te asigna al proyecto y te pide que ajustes un modelo beta-binomial "no informativo" para responder a la pregunta de investigación.

### Pregunta 13

-   ¿Cómo se representa la "tasa de aceptación" en el modelo?

::: {#respuesta-13 .callout-note}

Se representa como un parámetro de la distribución binomial, denotado con la letra $p$ para problemas de estadística "clásica", y en el caso de los análisis bayesianos, se utiliza la letra $\theta$ como se muestra en el libro de Hoff (2009).

:::

### Pregunta 14

-   ¿Qué distribución previa utilizarías para esa tasa de aceptación? Formúlala y represéntala gráficamente.

*(Ajusta los ejes correctamente, si hace falta, como en la distribución uniforme).*

::: {#respuesta-14 .callout-note}

Utilizaría una distribución previa no informativa; es decir, que los valores alfa y beta sean igual a 1:

```{r respuesta-14}

beta_previa <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = 1, shape2 = 1))

beta_previa |>
  ggplot(mapping = aes(x = variable, y = beta)) +
  geom_line(color = color_defecto) +
  ylim(0, uniforme |> pull(densidad) |> max())

```

:::

### Pregunta 15

-   Supón que $y$ es el número de usuarios/as que han respondido que "Sí" descargarían la app. Formula la verosimilitud del modelo.

::: {#respuesta-15 .callout-note}

Podría formularse como la siguiente ecuación matemática:

\begin{equation}
P(y \mid \theta, n) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}
\end{equation}

:::

## Ajuste del modelo

-   El departamento de investigación de mercado te da acceso a los siguientes datos de la muestra:

```{r beta-binomial-muestra}
aceptacion_muestra <- tibble(
  id_participante   = 1:22,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si"
  )
)

# Pequeño código para facilitar el contar las filas "Si":

aceptacion_muestra |> count(resp_descarga_app)

```

### Pregunta 16

-   Obtén, en base a estos datos, la distribución posterior de la tasa de aceptación (en forma analítica), y represéntala junto a la distribución previa.

::: {#respuesta-16 .callout-note}

En forma analítica (bayesiana), se estimaría de la siguiente manera:

```{r respuesta-16.1}
alpha_0 <- 1
beta_0 <- 1

alpha_n1 <- alpha_0 + 17
beta_n1 <-  beta_0 + 5

print(alpha_n1)
print(beta_n1)
```

De esta manera, la distribución posterior será:

\begin{equation}
\theta \mid datos \sim Beta(18,6)
\end{equation}

Y al estimarlo se obtiene la siguiente gráfica:

```{r respuesta-16.2}

beta_posterior <- tibble(variable = seq(from = 0, to = 1, PREC),
               beta = dbeta(variable, shape1 = alpha_n1, shape2 = beta_n1))

beta_ejemplos <- bind_rows(
  beta_previa %>% mutate(grupo = "Distribución beta previa"),
  beta_posterior %>% mutate(grupo = "Distribución beta posterior"))

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplos)

```

:::

### Pregunta 17

-   Obtén por el método numérico el valor esperado y la moda de la distribución posterior. ¿Cómo los interpretarías?

*(Nota: Ten en cuenta la "precisión" al calcular el "peso" de cada muestra.)*

::: {#respuesta-17 .callout-note}

El valor esperando teórico de la distribución beta posterior se obtiene por la siguiente fórmula:

\begin{equation}
\mathbb{E}[\theta] = \frac{\alpha}{\alpha + \beta}
\end{equation}

Mientras que al moda teórica de la distribución beta posterior se obtiene por la siguiente fórmula:

\begin{equation}
E(\theta) = \frac{\alpha - 1}{(\alpha + \beta - 2)}
\end{equation}

Si utilizáramos dichas fórmulas en el contexto de nuestro ejemplo, obtendríamos:

```{r respuesta-17.1}
# Media teórica de la distribución previa:

1/(alpha_0 + beta_0)

# Moda teórica de la distribución previa:

# Indefinido (como es una línea recta, todos los valores son infinitamente posibles)

# Media teórica de la distribución posterior:

alpha_n1 / (alpha_n1 + beta_n1)

# Moda teórica de la distribución posterior:

round((alpha_n1 - 1)/(alpha_n1 + beta_n1 -2), 3)
```

Sin embargo, de forma empírica las podríamos obtener de la siguiente manera:

```{r respuesta-17.2}
# Media empírica de la distribución previa

sum(beta_previa$variable * beta_previa$beta) * PREC

# Moda empírica de la distribución previa

beta_previa$beta[which.max(beta_previa$beta)]

# Media empírica de la distribución posterior

sum(beta_posterior$variable * beta_posterior$beta) * PREC

# Moda empírica de la distribución posterior

beta_posterior$variable[which.max(beta_posterior$beta)]

```
Por ambas formas de obtener la media y la moda, la distribución previa tiene una media de 0.5 y una moda de 1 para infinitos puntos. En cambio, en la distribución posterior los valores empíricos (media = 0.74998, moda = 0.7619) se aproximan a las estimaciones utilizando los parámetros alfa y beta (media = 0.75, moda = 0.773)

:::

## Ajuste con una nueva muestra

-   El director de investigación de mercado no está totalmente seguro con los resultados, y pide a su departamento recoger una nueva muestra, mayor, para el estudio. Te dan acceso a los siguientes datos de la nueva muestra:

```{r beta-binomial-muestra2}
aceptacion_muestra_2 <- tibble(
  id_participante   = 1:113,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si", 
    "No", "Si", "Si", "Si", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "Si", "Si", "Si", "No", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "No", "No", "No", "Si", "No", "No", "Si", "Si", "No", "No", "Si", 
    "No", "Si", "No", "No", "No", "Si", "Si", "No", "Si", "Si", "No", 
    "Si", "Si", "No", "Si", "Si", "No", "Si", "No", "Si", "No", "Si", 
    "No", "No", "No", "Si", "Si", "No", "No", "Si", "Si", "No", "No", 
    "No", "Si", "Si", "No", "Si", "Si", "No", "Si", "Si", "Si", "Si", 
    "No", "Si", "No", "No", "No", "No", "No", "Si", "No", "No", "Si", 
    "Si", "Si", "Si"
  )
)

aceptacion_muestra_2 |> count(resp_descarga_app)

```

### Pregunta 18

-   ¿Qué distribución previa utilizarías en esta ocasión? Formúlala.

::: {#respuesta-18 .callout-note}

Utilizaría la distribución de la muestra previa, ya que es información con la que ya contamos.

```{r respuesta-18.1}

beta_posterior |>
  ggplot(mapping = aes(x = variable, y = beta)) +
  geom_line(color = color_defecto)

```

Es decir, se utilizarían el alpha y beta de la distribución posterior anterior como previa de la actual.

:::

### Pregunta 19

-   Obtén la distribución posterior analítica después de esta segunda muestra, represéntala junto con las dos distribuciones anteriores, y obtén los estimadores posteriores esperado y modal usando el método numérico.

::: {#respuesta-19 .callout-note}

La nueva distribución posterior se estimaría a partir de los nuevos datos otorgados: 
```{r respuesta-19.1}

# Datos de la distribución previa

alpha_n1
beta_n1

# Datos de la distribución posterior

alpha_n2 <- alpha_n1 + 65
beta_n2 <- beta_n1 + 48

print(alpha_n2)
print(beta_n2)
```

Lo que resultaría en la siguiente progresión de distribuciones:

```{r respuesta-19.2}

beta_posterior2 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = alpha_n2, shape2 = beta_n2))

beta_ejemplos <- bind_rows(
  beta_previa %>% mutate(grupo = "Distribución beta previa 1"),
  beta_posterior %>% mutate(grupo = "Distribución beta previa 2"),
  beta_posterior2 %>% mutate(grupo = "Distribución beta posterior"))

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplos)

```
Media de esta nueva distribución posterior:

```{r respuesta-19.3}
# Forma analítica (bayesiana)

round( alpha_n2 /(alpha_n2 + beta_n2),3)

#Forma a través del cálculo aproximado

sum(beta_posterior2$variable * beta_posterior2$beta) * PREC
```

Moda de esta nueva distribución posterior:

```{r respuesta-19.4}

# Forma analítica (bayesiana)

round((alpha_n2 - 1)/(alpha_n2 + beta_n2 - 2), 3)

# Forma a través del cálculo aproximado

beta_posterior2$variable[which.max(beta_posterior2$beta)]

```

:::

## Ajuste con las muestras colapsadas

Supón que el director de investigación de mercado no estaba contento con la muestra inicial y pidió recoger más muestra antes de darte acceso a los datos.
Cuando recibes los datos, recibes las dos muestras colapsadas, sin saber qué participantes eran de la primera o de la segunda muestra:

```{r beta-binomial-muestra-total}
aceptacion_muestra_total <- bind_rows(
  aceptacion_muestra, aceptacion_muestra_2
) |>
  mutate(id_participante = row_number()) # Los ID están colapsados en una serie

aceptacion_muestra_total |> count(resp_descarga_app)
```

### Pregunta 20

-   Obtén la distribución posterior analítica después de esta segunda muestra, represéntala junto con las distribuciones anteriores, y obtén los estimadores posteriores esperado y modal por el método numérico.

::: {#respuesta-20 .callout-note}

Debido a que son los mismos datos (no hay ninguna observación nueva), entonces:

```{r respuesta-20.1}

alpha_n3 <- alpha_n2
beta_n3 <- beta_n2

print(alpha_n3)
print(beta_n3)
```

Lo que resultaría en la siguiente progresión de distribuciones:

```{r respuesta-20.2}

beta_posterior3 <- tibble(variable = seq(from = 0, to = 1, by = PREC),
               beta = dbeta(variable, shape1 = alpha_n3, shape2 = beta_n3))

beta_ejemplos <- bind_rows(
  beta_previa %>% mutate(grupo = "Distribución beta previa 1"),
  beta_posterior %>% mutate(grupo = "Distribución beta previa 2"),
  beta_posterior2 %>% mutate(grupo = "Distribución beta previa 3"),
  beta_posterior3 %>% mutate(grupo = "Distribución beta posterior"))

ggplot(beta_ejemplos, aes(x = variable, y = beta, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(beta_ejemplos$grupo)))

rm(beta_ejemplos)

```
Media de esta nueva distribución posterior:

```{r respuesta-20.3}

# Forma analítica (bayesiana)

round(alpha_n3 / (alpha_n3 + beta_n3), 3)

# Forma a través del cálculo aproximado

sum(beta_posterior3$variable * beta_posterior3$beta) * PREC

```

Moda de esta nueva distribución posterior:

```{r respuesta-20.4}

# Forma analítica (bayesiana)

round((alpha_n3 - 1)/(alpha_n3 + beta_n3 - 2), 3)

# Forma a través del cálculo aproximado

beta_posterior3$variable[which.max(beta_posterior3$beta)]
```

:::

### Pregunta 21

-   ¿Qué concluyes de la respuesta anterior? ¿En qué se diferencia este enfoque del análisis de datos clásico o frecuentista?

::: {#respuesta-21 .callout-note}

Que el enfoque desde la perspectiva bayesiana se aproxima de forma gradual a la certeza o verdad, a través de información previa. Así mismo, en el caso del último ejercicio, a pesar que nos den una base de datos con ambas recolecciones de información de forma junta y aleatorizada, sabemos que no hay ningún caso que brinde información nueva al modelo, por lo que las últimas dos distribuciones son de igual tamaño.

:::

# Ejercicio 4

*(NOTA: Para todas las distribuciones, utiliza el valor de `PREC` definido en el ejercicio 1.)*

En un proyecto de investigación educativo, el equipo investigador ha evaluado la rapidez de lectura en las dos clases de 1º de ESO de un colegio.
Los datos que te entregan consisten en el tiempo en segundos que tarda cada niño en leer un texto estandarizado.

Se quiere obtener un parámetro global promedio del tiempo de lectura para el alumnado de 1º de ESO en el colegio, para lo que te piden ajustar un modelo normal-normal.
Se pide usar como distribución previa la estimada de la población, que tiene media y varianza de 247 y 1156, respectivamente.

Los datos que te han facilitado son:

```{r normal-normal-muestras}
clase_1 <- tibble(
  id     = 1:27,
  tiempo = c(
    242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
    228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
    168, 250
  )
)

clase_2 <- tibble(
  id     = 1:24,
  tiempo = c(
    195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
    144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282
  )
)
```

## Modelo normal-normal

### Pregunta 22

-   Determina la verosimilitud y las distribuciones previa y posterior de la media, asumiendo que la varianza de la verosimilitud es la varianza de los datos. Justifica cómo has obtenido los parámetros de la distribución posterior (usa 2 decimales de precisión).

::: {#respuesta-22 .callout-note}

Para una distribución posterior normal-normal, la media posterior se puede calcular como:

\begin{equation}
\mu_n = \frac{
    \frac{\mu_0}{\sigma_0^2} + \frac{n \bar{y}}{\sigma^2}
}{
    \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}
}
\end{equation}

Y la varianza posterior como:

\begin{equation}
\sigma_n^2 = \left( \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2} \right)^{-1}
\end{equation}

Sabiendo que la distribución normal previa tiene una media de 247 y una varianza de 1156, y obteniendo que los datos de la muestra de alumnos tienen las siguientes características:

```{r respuesta-22.1}

clase_total <- rbind(clase_1, clase_2)

# Tamaño de la muestra de información:

length(clase_total$tiempo)

# Media

mean(clase_total$tiempo)

# Varianza

var(clase_total$tiempo)

```

Podríamos calcular la distribución normal-normal posterior (ambas con la misma varianza poblacional) aplicando la fórmula inicial:

```{r respuesta-22.2}

# Media posterior

mu_0 <- 247
sigma_sq_0 <- 1156

mu_n <- mean(clase_total$tiempo)

media_posterior_normal <- round(
  (mu_0/sigma_sq_0 + 51 * mu_n / sigma_sq_0) / (1/sigma_sq_0 + 51/sigma_sq_0))

print(media_posterior_normal)

# Varianza posterior

varianza_posterior_normal <- round(1 / (1/sigma_sq_0 + 51/sigma_sq_0))

print(varianza_posterior_normal)

```

:::

## Estimación

### Pregunta 23

-   Representa las distribuciones previa y posterior de la media; considera un eje que cubra 4 desviaciones típicas a cada lado de la media de la distribución previa. Obten el estimador esperado y modal a partir de esta distribución y compáralos con la solución analítica de la pregunta anterior.

::: {#respuesta-23 .callout-note}

La representación gráfica de las distribuciones previa y posterior son las siguientes:

```{r respuesta-23.1}

normal_previa <- tibble(variable = seq(from = 100, to = 400, by = PREC),
                        densidad = dnorm(variable, mean = 247, sd = sqrt(1156)))

normal_posterior <- tibble(variable = seq(from = 100, to = 400, by = PREC),
                        densidad = dnorm(variable, mean = 228, sd = sqrt(22)))

normal_ejemplo <- bind_rows(
  normal_previa %>% mutate(grupo = "Distribución normal previa"),
  normal_posterior %>% mutate(grupo = "Distribución normal posterior"))

ggplot(normal_ejemplo, aes(x = variable, y = densidad, color = grupo)) +
  geom_line() +
  scale_color_manual(name = "Leyenda", values = setNames(PALETA[1:6], unique(normal_ejemplo$grupo)))

rm(normal_ejemplo)

```

La estimación de la media y la moda de la distribución posterior se presenta a continuación:

```{r respuesta-23.2}

# Media de la distribución posterior

sum(normal_posterior$variable * normal_posterior$densidad) / sum(normal_posterior$densidad)

# Moda de la distribución posterior

normal_posterior$variable[which.max(normal_posterior$densidad)]
```

Tanto de la forma analítica (bayesiana) como en la forma aproximada, se obtiene el mismo valor de la media (228). De igual forma, sabemos que en una distribución normal, el valor de la media, mediana y moda es la misma, por ello el resultado igual entre las estimaciones previas.

:::
